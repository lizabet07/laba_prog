## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 3
### –ó–∞–¥–∞–Ω–∏–µ A ‚Äî src/lib/text.py
#### normalize - –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É –≤–∏–¥—É
```python
import re  # –º–æ–¥—É–ª—å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–µ–≥—É–ª—è—Ä–Ω—ã–º–∏ –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º–∏

def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    if not isinstance(text, str):
        raise TypeError

    text = re.sub(r'\s+', ' ', text)

    if yo2e:
        text = text.replace('—ë', '–µ').replace('–Å', '–ï')

    if casefold:
        text = text.casefold()

    return text.strip()
print(normalize("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t"))        
print(normalize("—ë–∂–∏–∫, –Å–ª–∫–∞")) 
print(normalize("Hello\r\nWorld"))      
print(normalize("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  "))
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/image01.png)

#### tokenize - —Ä–∞–∑–±–∏–≤–∞–µ—Ç —Å–ª–æ–≤–∞ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞/—á–∞—Å—Ç–∏
```python
import re
def tokenize(text: str) -> list[str]:
    if not isinstance(text,str):
        raise TypeError
    tokens = re.findall(r'[\w-]+', text) 
    return tokens
print(tokenize("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"))
print(tokenize("hello,world!!!"))
print(tokenize("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ"))
print(tokenize("2025 –≥–æ–¥"))
print(tokenize("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ"))
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/image02.png)

#### count_freq + top_n - —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç—Å—è –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ
```python
from collections import Counter  # —Ñ-–∏—è –¥–ª—è –ø–æ–¥—Å—á—ë—Ç–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π
def count_freq(tokens: list[str]) -> dict[str, int]:
    freq = Counter(tokens)
    return dict(freq) #–ø—Ä–µ–≤—Ä–∞—â–∞–µ–º –≤ —Å–ª–æ–≤–∞—Ä—å
def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
    sorted_items = sorted(freq.items(), key=lambda x: (-x[1], x[0]))
    # 1)–ø—Ä–æ–≤–µ—Ä–∞—â–∞–µ–º –≤ —Å–ø–∏—Å–æ–∫ —Å –∫–æ—Ä—Ç–µ–∂–∞–º–∏, 2)—Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —á–∞—Å—Ç–æ—Ç–µ, –ø–æ—Ç–æ–º –ø–æ —Ç–æ–∫–µ–Ω–∞–º
    return sorted_items[:n]
tokens1 = ["a","b","a","c","b","a"]
tokens2 = ["bb","aa","bb","aa","cc"]
freq1 = count_freq(["a","b","a","c","b","a"])
freq2 = count_freq(["bb","aa","bb","aa","cc"])
print(count_freq(["a","b","a","c","b","a"]))
print(top_n(freq1, n = 2))
print(count_freq(["bb","aa","bb","aa","cc"]))
print(top_n(freq2, n =2))
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/image03.png)

### –ó–∞–¥–∞–Ω–∏–µ B ‚Äî src/text_stats.py (—Å–∫—Ä–∏–ø—Ç —Å–æ stdin)
####–í–≤–æ–¥–∏–º –≤ PowerShell —ç—Ç—É –∫–æ–º–∞–Ω–¥—É –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–æ–¥–∏—Ä–æ–≤–∫–∏ Windows: $OutputEncoding = [System.Text.Encoding]::UTF8 –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ–∞–π–ª —Å —Ñ—É–Ω–∫—Ü–∏—è–º–∏ –∏ –ø—Ä–æ—Å—Ç–æ —Å–æ–∑–¥–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é —Å –≤—ã–≤–æ–¥–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞. –ü–æ—Å–ª–µ —Ñ—É–Ω–∫—Ü–∏–∏ —Å–æ–∑–¥–∞–µ–º —Å—Ç—Ä–æ–∫—É, –∫–æ—Ç–æ—Ä—É—é –ø—Ä–∏–Ω–∏–º–∞–µ–º –∏–∑ PowerShell (–∏ –¥–µ–∫–æ–¥–∏—Ä—É–µ–º –µ—ë)
```python
import sys
from text import *
def stats(text):

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
    text = normalize(text)

    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–ª–æ–≤–∞
    tokens = tokenize(text)

    # –ü–æ–¥—Å—á—ë—Ç —á–∞—Å—Ç–æ—Ç
    freq = count_freq(tokens)

    # –¢–æ–ø-5 —Å–ª–æ–≤
    top = top_n(freq, n=5)

    # –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {len(tokens)}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(freq)}")
    print("–¢–æ–ø-5:")
    for word, count in top:
        print(f"{word}:{count}")

text_in = sys.stdin.buffer.read().decode('utf-8')
stats(text_in)

```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/image04.png)
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/image.png)
